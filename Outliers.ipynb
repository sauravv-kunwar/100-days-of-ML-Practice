{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e99c10b-2c88-487e-9b4f-03a121acee49",
   "metadata": {},
   "source": [
    "# Outliers \n",
    "## 1. What are Outliers?\n",
    "- Definition: Data points that significantly differ from other observations in a dataset\n",
    "\n",
    "# Characteristics:\n",
    "\n",
    "- Unusual values compared to the rest of the data\n",
    "\n",
    "- Can occur due to:\n",
    "\n",
    "- Measurement errors\n",
    "\n",
    "- Data entry errors\n",
    "\n",
    "- Natural variation in data\n",
    "\n",
    "- Fraudulent activity\n",
    "\n",
    "- Experimental errors\n",
    "\n",
    "# Types:\n",
    "\n",
    "- Univariate outliers: Extreme values in a single feature/variable\n",
    "\n",
    "- Multivariate outliers: Unusual combinations of values across multiple features\n",
    "\n",
    "## 2. When are Outliers Dangerous?\n",
    "- Outliers become problematic when they:\n",
    "\n",
    "- Skew statistical analyses (mean, standard deviation)\n",
    "\n",
    "- Bias machine learning model training\n",
    "\n",
    "- Reduce model accuracy and performance\n",
    "\n",
    "- Violate assumptions of statistical methods (normality, homoscedasticity)\n",
    "\n",
    "- Mask important patterns in the data\n",
    "\n",
    "- Cause overfitting if model tries to accommodate them unnecessarily\n",
    "\n",
    "- Situations where outliers matter most:\n",
    "\n",
    "- Small datasets\n",
    "\n",
    "- Algorithms sensitive to scale and distribution\n",
    "\n",
    "- When making predictions for typical cases\n",
    "\n",
    "- When model interpretability is important\n",
    "\n",
    "## 3. Effect of Outliers on ML Algorithms\n",
    "- Linear Regression: Heavily influenced (especially with squared error loss)\n",
    "\n",
    "- K-Means Clustering: Can distort centroid positions\n",
    "\n",
    "- PCA (Principal Component Analysis: Can skew principal components\n",
    "\n",
    "- Tree-based algorithms (Random Forest, Decision Trees): Generally more robust\n",
    "\n",
    "- SVM (Support Vector Machines): Can affect margin and support vectors\n",
    "\n",
    "- Neural Networks: May slow convergence or lead to poor generalization\n",
    "\n",
    "- K-NN (K-Nearest Neighbors): Can affect distance calculations\n",
    "\n",
    "## 4. How to Treat Outliers\n",
    "- Options to handle outliers:\n",
    "## A. Removal\n",
    "\n",
    "- Delete outlier records (only if they're errors and dataset is large enough)\n",
    "\n",
    "- Risk: May lose valuable information\n",
    "\n",
    "##  B. Transformation\n",
    "\n",
    "- Log transformation\n",
    "\n",
    "- Square root transformation\n",
    "\n",
    "- Box-Cox transformation\n",
    "\n",
    "- Effect: Reduces impact of extreme values\n",
    "\n",
    " ## C. Imputation\n",
    "\n",
    "- Replace with:\n",
    "\n",
    "- Mean/median (for symmetric data)\n",
    "\n",
    "- Mode (for categorical)\n",
    "\n",
    "- Predictive values from models\n",
    "\n",
    "- Use winsorization (capping at certain percentiles)\n",
    "\n",
    "## D. Separate Modeling\n",
    "\n",
    "- Build separate models for outliers vs. normal data\n",
    "\n",
    "##  E. Use Robust Algorithms\n",
    "\n",
    "- Algorithms less sensitive to outliers\n",
    "\n",
    "## F. Binning/Discretization\n",
    "\n",
    "- Convert continuous values to categories\n",
    "\n",
    "## 5. How to Detect Outliers\n",
    "- Visual Methods:\n",
    "- Box plots (shows Q1, Q3, IQR, whiskers)\n",
    "\n",
    "- Scatter plots\n",
    "\n",
    "- Histograms\n",
    "\n",
    "- QQ plots (for normality checking)\n",
    "\n",
    "- Statistical Methods:\n",
    "- Z-score method: Values beyond ±3 standard deviations\n",
    "\n",
    "- IQR method: Values below Q1-1.5×IQR or above Q3+1.5×IQR\n",
    "\n",
    "- Modified Z-score: Uses median and MAD (Median Absolute Deviation)\n",
    "\n",
    "- ML-Based Methods:\n",
    "- Isolation Forest\n",
    "\n",
    "- Local Outlier Factor (LOF)\n",
    "\n",
    "- One-Class SVM\n",
    "\n",
    "- DBSCAN clustering (identifies points in low-density regions)\n",
    "\n",
    "## 6. Techniques for Outlier Detection\n",
    "## A. Univariate Methods\n",
    "- Z-Score Method\n",
    "\n",
    "text\n",
    "Z = (x - μ) / σ\n",
    "If |Z| > 3 → Potential outlier\n",
    "IQR Method\n",
    "\n",
    "text\n",
    "IQR = Q3 - Q1\n",
    "Lower bound = Q1 - 1.5 × IQR\n",
    "Upper bound = Q3 + 1.5 × IQR\n",
    "Percentile Method\n",
    "\n",
    "- Flag values below 5th or above 95th percentile\n",
    "\n",
    "## B. Multivariate Methods\n",
    "- Mahalanobis Distance\n",
    "\n",
    "- Measures distance from center considering correlations\n",
    "\n",
    "- DBSCAN\n",
    "\n",
    "- Identifies core, border, and noise points\n",
    "\n",
    "- Noise points = potential outliers\n",
    "\n",
    "- Isolation Forest\n",
    "\n",
    "- Builds random trees to isolate observations\n",
    "\n",
    "- Fewer splits needed to isolate outliers → higher anomaly score\n",
    "\n",
    "- Local Outlier Factor (LOF)\n",
    "\n",
    "- Compares local density of a point with its neighbors\n",
    "\n",
    "- Low density relative to neighbors = potential outlier\n",
    "\n",
    "- One-Class SVM\n",
    "\n",
    "- Learns a boundary around normal data\n",
    "\n",
    "- Points outside boundary = outliers\n",
    "\n",
    "- Autoencoders (Neural Networks)\n",
    "\n",
    "- Train on normal data\n",
    "\n",
    "- High reconstruction error = potential outlier\n",
    "\n",
    "## 7. Quick Decision Guide\n",
    "- When reviewing data:\n",
    "- Visualize first (box plots, scatter plots)\n",
    "\n",
    "- Check if outliers are errors → Remove/correct\n",
    "\n",
    "- Check impact on model metrics\n",
    "\n",
    "- Try multiple detection methods (different methods catch different outliers)\n",
    "\n",
    " - Consider domain knowledge (some \"outliers\" might be important)\n",
    "\n",
    "- Document decisions made about outliers\n",
    "\n",
    "- Rule of thumb:\n",
    "- Large dataset, clear errors: Remove\n",
    "\n",
    "- Small dataset, unclear if errors: Transform or use robust methods\n",
    "\n",
    "- Critical applications: Investigate each outlier thoroughly\n",
    "\n",
    "- Exploratory phase: Note them but don't automatically remove\n",
    "\n",
    "  ## 8. Key Takeaways\n",
    "- Not all outliers are bad - some represent important rare events\n",
    "\n",
    "- Always investigate outliers before deciding treatment\n",
    "\n",
    "- Choice of treatment depends on:\n",
    "\n",
    "- Dataset size\n",
    "\n",
    "- Problem context\n",
    "\n",
    "- Algorithm choice\n",
    "\n",
    "- Business implications\n",
    "\n",
    "- When in doubt, compare model performance with/without outlier treatment\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
